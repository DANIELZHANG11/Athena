"""
æ£€æŸ¥å¹¶æ’é˜Ÿå¤„ç†æ‰€æœ‰æœªOCRã€æœªå‘é‡åŒ–çš„ä¹¦ç±

ä½¿ç”¨æ–¹å¼:
    åœ¨ worker-gpu å®¹å™¨å†…è¿è¡Œ:
    cd /app && python -m scripts.check_and_queue_books

    å¯é€‰å‚æ•°:
    --check-only       ä»…æ£€æŸ¥ï¼Œä¸æ’é˜Ÿå¤„ç†
    --queue-ocr        æ’é˜Ÿéœ€è¦OCRçš„ä¹¦ç±
    --queue-vector     æ’é˜Ÿéœ€è¦å‘é‡ç´¢å¼•çš„ä¹¦ç±  
    --queue-all        æ’é˜Ÿæ‰€æœ‰éœ€è¦å¤„ç†çš„ä¹¦ç±
    --delay 5          æ¯ä¸ªä»»åŠ¡ä¹‹é—´çš„å»¶è¿Ÿç§’æ•°ï¼ˆæ¨¡æ‹Ÿå‰ç«¯ç”¨æˆ·ï¼‰

åŠŸèƒ½:
1. æ£€æŸ¥æ‰€æœ‰ä¹¦ç±çš„OCRçŠ¶æ€å’Œå‘é‡ç´¢å¼•çŠ¶æ€
2. è¯†åˆ«éœ€è¦OCRçš„å›¾ç‰‡å‹PDF
3. è¯†åˆ«éœ€è¦å‘é‡ç´¢å¼•çš„ä¹¦ç±ï¼ˆåŒ…æ‹¬å·²å®ŒæˆOCRçš„PDFå’ŒEPUBï¼‰
4. å°†ä»»åŠ¡ä¸€ä¸ªä¸€ä¸ªåœ°æ’å…¥Celeryé˜Ÿåˆ—ï¼ˆä½¿ç”¨countdownå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿå‰ç«¯ç”¨æˆ·ï¼‰
"""

import argparse
import asyncio
import logging
import sys
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ  app ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, "/app")

from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("check_queue")

# æ•°æ®åº“è¿æ¥
DATABASE_URL = "postgresql+asyncpg://athena:athena_dev@pgbouncer:6432/athena"


async def get_all_books_status(engine) -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰ä¹¦ç±çš„çŠ¶æ€"""
    async with engine.connect() as conn:
        result = await conn.execute(
            text("""
                SELECT 
                    id, 
                    user_id,
                    title, 
                    author,
                    original_format,
                    minio_key,
                    is_digitalized,
                    initial_digitalization_confidence,
                    ocr_status,
                    ocr_requested_at,
                    vector_indexed_at,
                    content_sha256,
                    deleted_at,
                    created_at
                FROM books 
                WHERE deleted_at IS NULL
                ORDER BY created_at ASC
            """)
        )
        
        books = []
        for row in result.fetchall():
            books.append({
                "id": str(row[0]),
                "user_id": str(row[1]),
                "title": row[2],
                "author": row[3],
                "original_format": row[4],
                "minio_key": row[5],
                "is_digitalized": row[6],
                "confidence": float(row[7]) if row[7] else None,
                "ocr_status": row[8],
                "ocr_requested_at": row[9],
                "vector_indexed_at": row[10],
                "content_sha256": row[11],
                "created_at": row[13],
            })
        
        return books


def analyze_book_status(book: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆ†æå•æœ¬ä¹¦çš„å¤„ç†çŠ¶æ€
    
    è¿”å›:
        - needs_ocr: bool - æ˜¯å¦éœ€è¦OCR
        - needs_vector: bool - æ˜¯å¦éœ€è¦å‘é‡ç´¢å¼•
        - ocr_reason: str - OCRéœ€æ±‚åŸå› 
        - vector_reason: str - å‘é‡ç´¢å¼•éœ€æ±‚åŸå› 
    """
    result = {
        "needs_ocr": False,
        "needs_vector": False,
        "ocr_reason": None,
        "vector_reason": None,
        "ready_for_vector": False,  # æ˜¯å¦å¯ä»¥ç«‹å³å»ºå‘é‡ç´¢å¼•
    }
    
    fmt = book["original_format"]
    is_digitalized = book["is_digitalized"]
    confidence = book["confidence"]
    ocr_status = book["ocr_status"]
    vector_indexed_at = book["vector_indexed_at"]
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾ç‰‡å‹PDFï¼ˆéœ€è¦OCRï¼‰
    is_image_pdf = False
    if fmt == "pdf":
        # å›¾ç‰‡å‹ PDF: is_digitalized=False æˆ– confidence < 0.8
        if is_digitalized is False:
            is_image_pdf = True
        elif is_digitalized is True and confidence is not None and confidence < 0.8:
            is_image_pdf = True
    
    # OCR éœ€æ±‚åˆ¤æ–­
    if is_image_pdf:
        if ocr_status is None:
            result["needs_ocr"] = True
            result["ocr_reason"] = "å›¾ç‰‡å‹PDFï¼Œæœªå¼€å§‹OCR"
        elif ocr_status == "pending":
            result["needs_ocr"] = True
            result["ocr_reason"] = "å›¾ç‰‡å‹PDFï¼ŒOCRæ’é˜Ÿä¸­"
        elif ocr_status == "failed":
            result["needs_ocr"] = True
            result["ocr_reason"] = "å›¾ç‰‡å‹PDFï¼ŒOCRå¤±è´¥éœ€é‡è¯•"
        elif ocr_status == "processing":
            result["ocr_reason"] = "OCRå¤„ç†ä¸­"
        elif ocr_status == "completed":
            result["ocr_reason"] = "OCRå·²å®Œæˆ"
            result["ready_for_vector"] = True
    else:
        # éå›¾ç‰‡å‹PDFæˆ–EPUBï¼Œå¯ä»¥ç›´æ¥å»ºå‘é‡ç´¢å¼•
        if fmt in ["pdf", "epub"]:
            result["ready_for_vector"] = True
    
    # å‘é‡ç´¢å¼•éœ€æ±‚åˆ¤æ–­
    if vector_indexed_at is None:
        if result["ready_for_vector"]:
            result["needs_vector"] = True
            if fmt == "epub":
                result["vector_reason"] = "EPUBï¼Œæœªå»ºç«‹å‘é‡ç´¢å¼•"
            elif is_image_pdf and ocr_status == "completed":
                result["vector_reason"] = "å›¾ç‰‡å‹PDFå·²å®ŒæˆOCRï¼Œæœªå»ºç«‹å‘é‡ç´¢å¼•"
            else:
                result["vector_reason"] = "æ–‡å­—å‹PDFï¼Œæœªå»ºç«‹å‘é‡ç´¢å¼•"
        elif is_image_pdf and ocr_status != "completed":
            result["vector_reason"] = "ç­‰å¾…OCRå®Œæˆåæ‰èƒ½å»ºç«‹å‘é‡ç´¢å¼•"
        else:
            result["vector_reason"] = "æ ¼å¼ä¸æ”¯æŒæˆ–æ¡ä»¶ä¸æ»¡è¶³"
    else:
        result["vector_reason"] = f"å·²äº {vector_indexed_at} å»ºç«‹å‘é‡ç´¢å¼•"
    
    return result


def print_status_report(books: List[Dict[str, Any]]):
    """æ‰“å°çŠ¶æ€æŠ¥å‘Š"""
    total = len(books)
    needs_ocr = []
    needs_vector = []
    ocr_in_progress = []
    fully_indexed = []
    other = []
    
    for book in books:
        status = analyze_book_status(book)
        book["_status"] = status
        
        if status["needs_ocr"]:
            needs_ocr.append(book)
        elif status["needs_vector"]:
            needs_vector.append(book)
        elif book["vector_indexed_at"] is not None:
            fully_indexed.append(book)
        elif book["ocr_status"] == "processing":
            ocr_in_progress.append(book)
        else:
            other.append(book)
    
    print("\n" + "=" * 70)
    print("ğŸ“š ä¹¦ç±å¤„ç†çŠ¶æ€æŠ¥å‘Š")
    print("=" * 70)
    print(f"\nğŸ“Š æ€»è®¡: {total} æœ¬ä¹¦ç±")
    print(f"   âœ… å·²å®Œæˆå‘é‡ç´¢å¼•: {len(fully_indexed)}")
    print(f"   ğŸ”„ OCRå¤„ç†ä¸­: {len(ocr_in_progress)}")
    print(f"   â³ éœ€è¦OCR: {len(needs_ocr)}")
    print(f"   ğŸ“¦ éœ€è¦å‘é‡ç´¢å¼•: {len(needs_vector)}")
    print(f"   â“ å…¶ä»–: {len(other)}")
    
    if needs_ocr:
        print("\n" + "-" * 70)
        print("â³ éœ€è¦ OCR çš„ä¹¦ç±:")
        print("-" * 70)
        for book in needs_ocr:
            print(f"  ğŸ“• {book['title'][:40]:<40}")
            print(f"     ID: {book['id']}")
            print(f"     æ ¼å¼: {book['original_format']}, ç½®ä¿¡åº¦: {book['confidence']}")
            print(f"     çŠ¶æ€: {book['_status']['ocr_reason']}")
    
    if needs_vector:
        print("\n" + "-" * 70)
        print("ğŸ“¦ éœ€è¦å‘é‡ç´¢å¼•çš„ä¹¦ç±:")
        print("-" * 70)
        for book in needs_vector:
            print(f"  ğŸ“— {book['title'][:40]:<40}")
            print(f"     ID: {book['id']}")
            print(f"     æ ¼å¼: {book['original_format']}")
            print(f"     åŸå› : {book['_status']['vector_reason']}")
    
    if fully_indexed:
        print("\n" + "-" * 70)
        print("âœ… å·²å®Œæˆå…¨éƒ¨å¤„ç†çš„ä¹¦ç±:")
        print("-" * 70)
        for book in fully_indexed:
            print(f"  ğŸ“˜ {book['title'][:50]}")
            print(f"     å‘é‡ç´¢å¼•: {book['vector_indexed_at']}")
    
    print("\n" + "=" * 70)
    
    return {
        "total": total,
        "needs_ocr": needs_ocr,
        "needs_vector": needs_vector,
        "ocr_in_progress": ocr_in_progress,
        "fully_indexed": fully_indexed,
        "other": other,
    }


def queue_tasks(report: Dict, delay_seconds: int = 5, queue_ocr: bool = True, queue_vector: bool = True):
    """
    å°†ä»»åŠ¡æ’å…¥Celeryé˜Ÿåˆ—
    
    ä½¿ç”¨ countdown å‚æ•°å®ç°å»¶è¿Ÿæ‰§è¡Œï¼Œæ¨¡æ‹Ÿå‰ç«¯ç”¨æˆ·ä¸€ä¸ªä¸€ä¸ªä¸Šä¼ ä¹¦ç±çš„è¡Œä¸ºã€‚
    è¿™æ ·å¯ä»¥é¿å…ä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡å¯¼è‡´ç³»ç»Ÿè¿‡è½½ã€‚
    """
    from app.celery_app import celery_app
    
    queued_ocr = 0
    queued_vector = 0
    current_delay = 0
    
    # æ’é˜ŸOCRä»»åŠ¡
    if queue_ocr and report["needs_ocr"]:
        print("\nğŸš€ æ­£åœ¨æ’é˜ŸOCRä»»åŠ¡...")
        for book in report["needs_ocr"]:
            book_id = book["id"]
            user_id = book["user_id"]
            title = book["title"]
            
            # ä½¿ç”¨ countdown å»¶è¿Ÿæ‰§è¡Œ
            celery_app.send_task(
                "tasks.process_book_ocr",
                args=[book_id, user_id],
                countdown=current_delay,
            )
            
            queued_ocr += 1
            print(f"   âœ“ [{queued_ocr}] {title[:40]} (å»¶è¿Ÿ {current_delay}s)")
            current_delay += delay_seconds
    
    # æ’é˜Ÿå‘é‡ç´¢å¼•ä»»åŠ¡
    if queue_vector and report["needs_vector"]:
        print("\nğŸš€ æ­£åœ¨æ’é˜Ÿå‘é‡ç´¢å¼•ä»»åŠ¡...")
        for book in report["needs_vector"]:
            book_id = book["id"]
            title = book["title"]
            
            # ä½¿ç”¨ countdown å»¶è¿Ÿæ‰§è¡Œ
            celery_app.send_task(
                "tasks.index_book_vectors",
                args=[book_id],
                countdown=current_delay,
            )
            
            queued_vector += 1
            print(f"   âœ“ [{queued_vector}] {title[:40]} (å»¶è¿Ÿ {current_delay}s)")
            current_delay += delay_seconds
    
    print(f"\nğŸ“‹ ä»»åŠ¡æ’é˜Ÿå®Œæˆ:")
    print(f"   OCRä»»åŠ¡: {queued_ocr} ä¸ª")
    print(f"   å‘é‡ç´¢å¼•ä»»åŠ¡: {queued_vector} ä¸ª")
    print(f"   æ€»é¢„è®¡æ—¶é—´: {current_delay}s (ä¸å«å®é™…å¤„ç†æ—¶é—´)")
    
    return queued_ocr, queued_vector


async def verify_opensearch_vectors():
    """éªŒè¯OpenSearchä¸­çš„å‘é‡æ•°æ®"""
    try:
        from opensearchpy import AsyncOpenSearch
        
        client = AsyncOpenSearch(hosts=["http://opensearch:9200"])
        
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            exists = await client.indices.exists(index="athena_book_chunks")
            if not exists:
                print("\nâš ï¸ OpenSearch ç´¢å¼• 'athena_book_chunks' ä¸å­˜åœ¨")
                return
            
            # è·å–æ–‡æ¡£æ€»æ•°
            count_resp = await client.count(index="athena_book_chunks")
            total_chunks = count_resp.get("count", 0)
            
            # è·å–æ¯æœ¬ä¹¦çš„å—æ•°
            agg_resp = await client.search(
                index="athena_book_chunks",
                body={
                    "size": 0,
                    "aggs": {
                        "books": {
                            "terms": {
                                "field": "metadata.book_id.keyword",
                                "size": 100,
                            }
                        }
                    }
                }
            )
            
            book_stats = {}
            for bucket in agg_resp["aggregations"]["books"]["buckets"]:
                book_stats[bucket["key"]] = bucket["doc_count"]
            
            print("\n" + "-" * 70)
            print("ğŸ” OpenSearch å‘é‡ç´¢å¼•éªŒè¯:")
            print("-" * 70)
            print(f"   æ€»æ–‡æ¡£æ•°: {total_chunks}")
            print(f"   å·²ç´¢å¼•ä¹¦ç±æ•°: {len(book_stats)}")
            
            if book_stats:
                print("   å„ä¹¦ç±ç´¢å¼•å—æ•°:")
                for book_id, count in sorted(book_stats.items(), key=lambda x: x[1], reverse=True):
                    print(f"     - {book_id[:8]}...: {count} chunks")
            
        finally:
            await client.close()
            
    except Exception as e:
        print(f"\nâš ï¸ OpenSearch éªŒè¯å¤±è´¥: {e}")


async def main():
    parser = argparse.ArgumentParser(description="æ£€æŸ¥å¹¶æ’é˜Ÿå¤„ç†æ‰€æœ‰æœªOCRã€æœªå‘é‡åŒ–çš„ä¹¦ç±")
    parser.add_argument("--check-only", action="store_true", help="ä»…æ£€æŸ¥ï¼Œä¸æ’é˜Ÿå¤„ç†")
    parser.add_argument("--queue-ocr", action="store_true", help="æ’é˜Ÿéœ€è¦OCRçš„ä¹¦ç±")
    parser.add_argument("--queue-vector", action="store_true", help="æ’é˜Ÿéœ€è¦å‘é‡ç´¢å¼•çš„ä¹¦ç±")
    parser.add_argument("--queue-all", action="store_true", help="æ’é˜Ÿæ‰€æœ‰éœ€è¦å¤„ç†çš„ä¹¦ç±")
    parser.add_argument("--delay", type=int, default=5, help="æ¯ä¸ªä»»åŠ¡ä¹‹é—´çš„å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤5ç§’ï¼‰")
    parser.add_argument("--verify", action="store_true", help="éªŒè¯OpenSearchä¸­çš„å‘é‡æ•°æ®")
    
    args = parser.parse_args()
    
    start_time = datetime.now()
    logger.info("=" * 60)
    logger.info("[Check] å¼€å§‹æ£€æŸ¥ä¹¦ç±å¤„ç†çŠ¶æ€")
    logger.info("=" * 60)
    
    # åˆ›å»ºæ•°æ®åº“å¼•æ“
    engine = create_async_engine(DATABASE_URL, pool_pre_ping=True)
    
    try:
        # è·å–æ‰€æœ‰ä¹¦ç±çŠ¶æ€
        logger.info("\n[Step 1] è·å–æ‰€æœ‰ä¹¦ç±çŠ¶æ€...")
        books = await get_all_books_status(engine)
        logger.info(f"[Check] æ‰¾åˆ° {len(books)} æœ¬ä¹¦ç±")
        
        # æ‰“å°çŠ¶æ€æŠ¥å‘Š
        report = print_status_report(books)
        
        # éªŒè¯OpenSearch
        if args.verify:
            await verify_opensearch_vectors()
        
        # æ’é˜Ÿä»»åŠ¡
        if args.check_only:
            print("\nğŸ“ ä»…æ£€æŸ¥æ¨¡å¼ï¼Œä¸æ’é˜Ÿä»»åŠ¡")
        elif args.queue_all:
            queue_tasks(report, args.delay, queue_ocr=True, queue_vector=True)
        elif args.queue_ocr or args.queue_vector:
            queue_tasks(report, args.delay, queue_ocr=args.queue_ocr, queue_vector=args.queue_vector)
        else:
            print("\nğŸ’¡ æç¤º: ä½¿ç”¨ä»¥ä¸‹å‚æ•°æ’é˜Ÿä»»åŠ¡:")
            print("   --queue-ocr     æ’é˜Ÿéœ€è¦OCRçš„ä¹¦ç±")
            print("   --queue-vector  æ’é˜Ÿéœ€è¦å‘é‡ç´¢å¼•çš„ä¹¦ç±")
            print("   --queue-all     æ’é˜Ÿæ‰€æœ‰éœ€è¦å¤„ç†çš„ä¹¦ç±")
            print("   --delay N       æ¯ä¸ªä»»åŠ¡ä¹‹é—´å»¶è¿ŸNç§’ï¼ˆé»˜è®¤5ç§’ï¼‰")
            print("   --verify        éªŒè¯OpenSearchä¸­çš„å‘é‡æ•°æ®")
        
        # æ‰“å°æ€»ç»“
        duration = (datetime.now() - start_time).total_seconds()
        print(f"\nâ±ï¸ æ£€æŸ¥è€—æ—¶: {duration:.1f}s")
        
    finally:
        await engine.dispose()


if __name__ == "__main__":
    asyncio.run(main())
