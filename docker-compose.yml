services:
  traefik:
    image: zukubq0aouv2k2.xuanyuan.run/traefik:v3.0
    command:
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --entrypoints.web.address=:80
      - --api.insecure=true
    ports:
      - "80:80"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - api
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  api:
    build:
      context: ./api
    env_file:
      - .env
      - .env.local
      - .env.infisical
    environment:
      ES_URL: http://opensearch:9200
      REDIS_URL: redis://valkey:6379
      REDIS_HOST: valkey
      REDIS_PORT: 6379
      SENTRY_DSN: ""
      DATABASE_URL: postgresql+asyncpg://athena:${POSTGRES_PASSWORD}@pgbouncer:6432/athena
      CELERY_BROKER_URL: redis://valkey:6379/0
      CELERY_BACKEND_URL: redis://valkey:6379/1
      MINIO_PUBLIC_ENDPOINT: http://localhost:8333
      MINIO_ENDPOINT: seaweed:8333
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      MINIO_BUCKET: athena
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      SMTP_FROM_EMAIL: ${SMTP_FROM_EMAIL}
      SMTP_USE_SSL: ${SMTP_USE_SSL}
      PAY_FAKE_WEBHOOK_SECRET: devsecret
    labels:
      - traefik.enable=true
      - traefik.http.routers.api.rule=Host(`api.youdomin.com`)
      - traefik.http.routers.api.entrypoints=web
      - traefik.http.services.api.loadbalancer.server.port=8000
      - traefik.http.middlewares.api-ratelimit.ratelimit.average=100
      - traefik.http.middlewares.api-ratelimit.ratelimit.burst=50
      - traefik.http.routers.api.middlewares=api-ratelimit
      - traefik.http.routers.api-local.rule=Host(`localhost`)
      - traefik.http.routers.api-local.entrypoints=web
      - traefik.http.routers.api-local.middlewares=api-ratelimit
      - traefik.http.routers.api-local.service=api
    depends_on:
      - pgbouncer
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./api:/app
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  prometheus:
    image: zukubq0aouv2k2.xuanyuan.run/prom/prometheus:latest
    command: [ "--config.file=/etc/prometheus/prometheus.yml" ]
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
    depends_on:
      - api
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  grafana:
    image: zukubq0aouv2k2.xuanyuan.run/grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
      - loki
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    command: [ "-config.file=/etc/loki/local-config.yaml" ]
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  jaeger:
    image: jaegertracing/all-in-one:1.56
    ports:
      - "16686:16686"
      - "6831:6831/udp"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    depends_on:
      - api
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  backup:
    image: zukubq0aouv2k2.xuanyuan.run/postgres:16
    profiles: [ "manual" ]
    entrypoint: [ "bash", "-lc", "pg_dump -h postgres -U ${POSTGRES_USER} -d ${POSTGRES_DB} | gzip > /backups/athena_$(date +%Y%m%d_%H%M).sql.gz" ]
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ./backups:/backups
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  postgres:
    image: zukubq0aouv2k2.xuanyuan.run/ankane/pgvector:latest
    environment:
      - POSTGRES_USER=athena
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=athena
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "athena" ]
      interval: 10s
      timeout: 5s
      retries: 10
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  valkey:
    image: zukubq0aouv2k2.xuanyuan.run/redis:7
    command: [ "redis-server", "--appendonly", "yes" ]
    volumes:
      - valkey_data:/data
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  seaweed:
    image: zukubq0aouv2k2.xuanyuan.run/chrislusf/seaweedfs:latest
    command: [ "server", "-s3", "-s3.port=8333", "-s3.allowedOrigins=*", "-dir=/data" ]
    ports:
      - "8333:8333"
      - "8888:8888"
    volumes:
      - seaweed_data:/data
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  opensearch:
    # 使用自定义构建以包含 IK/Pinyin/STConvert 插件
    build:
      context: ./docker/opensearch
    image: athena-opensearch:custom
    environment:
      - discovery.type=single-node
      - DISABLE_SECURITY_PLUGIN=true
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9200/_cluster/health" ]
      interval: 10s
      timeout: 5s
      retries: 10
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  pgbouncer:
    image: zukubq0aouv2k2.xuanyuan.run/brainsam/pgbouncer:latest
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=athena
      - DB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_NAME=athena
      - POOL_MODE=session
      - MAX_CLIENT_CONN=200
      - DEFAULT_POOL_SIZE=20
      - LISTEN_PORT=6432
    depends_on:
      - postgres
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"

  # -------------------------------------------------------------------------
  # Tolgee (Translation Platform)
  # -------------------------------------------------------------------------
  tolgee_db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: tolgee
      POSTGRES_PASSWORD: tolgee_password
      POSTGRES_DB: tolgee
    volumes:
      - tolgee_postgres_data:/var/lib/postgresql/data
    networks:
      - athena-network

  tolgee:
    image: tolgee/tolgee:latest
    ports:
      - "8085:8080"
    environment:
      TOLGEE_DB_URL: jdbc:postgresql://tolgee_db:5432/tolgee
      TOLGEE_DB_USER: tolgee
      TOLGEE_DB_PASSWORD: tolgee_password
      TOLGEE_AUTHENTICATION_ENABLED: true
      TOLGEE_AUTHENTICATION_INITIAL_USERNAME: admin
      TOLGEE_AUTHENTICATION_INITIAL_PASSWORD: admin
    depends_on:
      - tolgee_db
    networks:
      - athena-network

  calibre:
    image: zukubq0aouv2k2.xuanyuan.run/linuxserver/calibre:latest
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Shanghai
    volumes:
      - calibre_config:/config
      - calibre_books:/books
      - ./scripts/calibre-convert-watcher.sh:/scripts/convert-watcher.sh:ro
    ports:
      - "8080:8080"
      - "8081:8081"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
  # Calibre 转换监控器 - 监听转换请求并执行 ebook-convert
  calibre-watcher:
    image: zukubq0aouv2k2.xuanyuan.run/linuxserver/calibre:latest
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Shanghai
    volumes:
      - calibre_books:/books
      - ./scripts/calibre-convert-watcher.sh:/scripts/convert-watcher.sh:ro
    # 启动时运行 watcher 脚本
    entrypoint: ["/bin/bash", "/scripts/convert-watcher.sh"]
    command: []
    depends_on:
      - calibre
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "2"
  worker:
    build:
      context: ./api
      args:
        SKIP_HEAVY: "false"  # 安装 PaddleOCR + BGE-M3 + EdgeTTS
    environment:
      - CELERY_BROKER_URL=redis://valkey:6379/0
      - CELERY_BACKEND_URL=redis://valkey:6379/1
      - DATABASE_URL=postgresql+asyncpg://athena:athena@pgbouncer:6432/athena
      - MINIO_ENDPOINT=seaweed:8333
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - MINIO_BUCKET=athena
      - CALIBRE_CONVERT_DIR=/calibre_books
      # OCR 配置 (PP-OCRv5 mobile)
      - OCR_USE_GPU=true
      - OCR_GPU_MEM=3500
      - OCR_CPU_THREADS=6
      - OCR_LANG=ch
      # Embedding 配置 (BGE-M3)
      - EMBEDDING_MODEL_NAME=BAAI/bge-m3
      - HF_HOME=/app/.hf_cache
      # GPU 内存控制
      - FLAGS_fraction_of_gpu_memory_to_use=0.4
    # 2 Workers（开发环境 8GB GPU）
    # 生产环境 12GB GPU 可改为 --concurrency=3
    command: ["celery", "-A", "app.celery_app.celery_app", "worker", "-l", "INFO", "--concurrency=2", "--pool=prefork", "--max-tasks-per-child=50"]
    depends_on:
      - valkey
      - pgbouncer
      - seaweed
      - opensearch
    volumes:
      - ./api:/app
      - calibre_books:/calibre_books
      - hf_cache:/app/.hf_cache
    # GPU 支持（需要 nvidia-docker）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
volumes:
  pg_data:
  valkey_data:
  seaweed_data:
  calibre_config:
  calibre_books:
  tolgee_postgres_data:
  opensearch_data:       # OpenSearch 向量索引数据
  hf_cache:              # HuggingFace 模型缓存 (BGE-M3)


networks:
  athena-network:
    driver: bridge
